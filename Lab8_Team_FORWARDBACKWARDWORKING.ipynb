{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9180e400",
   "metadata": {},
   "source": [
    "## Object Following (50 pts)\n",
    "\n",
    "In this notebook we'll show how you can follow an object with the crazyflie!  We'll use a pre-trained neural network that was trained on the [COCO dataset](http://cocodataset.org) to detect 90 different common objects.  These include\n",
    "\n",
    "* Person (index 0)\n",
    "* Cup (index 47)\n",
    "\n",
    "and many others (you can check [this file](https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_complete_label_map.pbtxt) for a full list of class indices). We use the MobileNet SSD (Single Shot Detector) trained on the COCO dataset. SSD models are often faster than other detection models and the MobileNet backbone is less computationally intensive, so this will help for real-time execution! The model is sourced from the [TensorFlow object detection API](https://github.com/tensorflow/models/tree/master/research/object_detection),\n",
    "which provides utilities for training object detectors for custom tasks also!\n",
    "\n",
    "We won't run through all of the training and optimization steps in this notebook though. The goal here is to demonstrate what one can do with neural networks. \n",
    "\n",
    "Anyways, let's get started!  First, we will load the pre-trained network. Make sure to have the Lab8_Supplement directory downloaded. Also download the model and place in the Lab8_Supplement directory [https://drive.google.com/file/d/1vIS9XySf5kdmVqPCtCpHG_-FL6RB8oOP/view](https://drive.google.com/file/d/1vIS9XySf5kdmVqPCtCpHG_-FL6RB8oOP/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e35757",
   "metadata": {},
   "source": [
    "### Compute detections on single camera image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379cb92",
   "metadata": {},
   "source": [
    "For this lab, we will be using OpenCV's DNN module which provides us with functionalities for deep learning inference. You can read more about how we are using it for [object detection](https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/). Specifically, we can load in the MobileNet SSD network that was trained using the Tensorflow framework. OpenCV's DNN module allows for multi-framework use (e.g., PyTorch and Caffe).\n",
    "\n",
    "First, we load in the COCO class names (e.g., person, potted plant, etc.), assign colors to the classes (this is useful for visualizing bounding boxes), and load the weights of the pre-trained neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11388b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "    \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "                        framework='TensorFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e4523",
   "metadata": {},
   "source": [
    "Now we will prepare an image for object detection with our model. `blobFromImage()` prepares the image into the correct format for our model. Specifically, we resize our input image to 300x300 and normalize the RGB channels with the mean parameter. Then we forward propagate the image through the model to obtain the detections. Each detection is of the form ( _, class_id, confidence, box_x, box_y, box_width, box_height) where box_x, box_y, box_width, box_height provide information for creating the bounding box of around the detected object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94efb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image from disk\n",
    "image = cv2.imread('Lab8_Supplement/Lab8_image.jpg')\n",
    "image_height, image_width, _ = image.shape\n",
    "\n",
    "# create blob from image\n",
    "blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), \n",
    "                             swapRB=True)\n",
    "\n",
    "# create blob from image\n",
    "model.setInput(blob)\n",
    "\n",
    "# forward pass through the model to carry out the detection\n",
    "detections = model.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad334d",
   "metadata": {},
   "source": [
    "Next we visualize the detections. You should see a bounding box, classification, and confidence value appear around each COCO object (potted plant and cup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7bea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over each of the detection\n",
    "for detection in detections[0, 0, :, :]:\n",
    "    # extract the confidence of the detection\n",
    "    confidence = detection[2]\n",
    "    # draw bounding boxes only if the detection confidence is above...\n",
    "    # ... a certain threshold, else skip\n",
    "    if confidence > .4:\n",
    "        # get the class id\n",
    "        class_id = detection[1]\n",
    "        # map the class id to the class\n",
    "        class_name = class_names[int(class_id)-1]\n",
    "        color = COLORS[int(class_id)]\n",
    "        # get the bounding box coordinates\n",
    "        box_x = detection[3] * image_width\n",
    "        box_y = detection[4] * image_height\n",
    "        # get the bounding box width and height\n",
    "        box_width = detection[5] * image_width\n",
    "        box_height = detection[6] * image_height\n",
    "        # draw a rectangle around each detected object\n",
    "        cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=1)\n",
    "        # put the FPS text on top of the frame\n",
    "        text = class_name + ' ' + '%.2f' % (confidence)\n",
    "        cv2.putText(image, text, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, 1)\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow('image', image)\n",
    "    \n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('Lab8_Supplement/image_result.jpg', image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c85278",
   "metadata": {},
   "source": [
    "To print just the first object detected in the example image, we could call the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2b2630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         64.          0.8862912   0.3806074   0.31562245  0.61905956\n",
      "  0.71215916]\n"
     ]
    }
   ],
   "source": [
    "object_number = 0\n",
    "print(detections[0, 0, object_number, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76512e87",
   "metadata": {},
   "source": [
    "### Compute detections on a live video feed\n",
    "\n",
    "The following cell will perform the same object detection and labeling on a live feed from your CrazyFlie camera! Note that the drone will not fly, you are simply using the camera. This should give you a sense of appropriate distances for detection, as well as the confidence for the detection of different objects from the Coco dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5196c776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4.646] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "# This may open your webcam instead of the CrazyFlie camera! If so, try\n",
    "# a different small, positive integer, e.g. 1, 2, 3.\n",
    "camera = 0\n",
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image_height, image_width, _ = frame.shape\n",
    "\n",
    "    # create blob from image\n",
    "    blob = cv2.dnn.blobFromImage(image=frame, size=(300, 300), mean=(104, 117, 123), \n",
    "                                 swapRB=True)\n",
    "\n",
    "    # create blob from image\n",
    "    model.setInput(blob)\n",
    "\n",
    "    # forward pass through the model to carry out the detection\n",
    "    detections = model.forward()\n",
    "\n",
    "    # loop over each of the detection\n",
    "    for detection in detections[0, 0, :, :]:\n",
    "        # extract the confidence of the detection\n",
    "        confidence = detection[2]\n",
    "        # draw bounding boxes only if the detection confidence is above...\n",
    "        # ... a certain threshold, else skip\n",
    "        if confidence > .4:\n",
    "            # get the class id\n",
    "            class_id = detection[1]\n",
    "            # map the class id to the class\n",
    "            class_name = class_names[int(class_id)-1]\n",
    "            color = COLORS[int(class_id)]\n",
    "            # get the bounding box coordinates\n",
    "            box_x = detection[3] * image_width\n",
    "            box_y = detection[4] * image_height\n",
    "            # get the bounding box width and height\n",
    "            box_width = detection[5] * image_width\n",
    "            box_height = detection[6] * image_height\n",
    "            # draw a rectangle around each detected object\n",
    "            cv2.rectangle(frame, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=1)\n",
    "            # put the FPS text on top of the frame\n",
    "            text = class_name + ' ' + '%.2f' % (confidence)\n",
    "            cv2.putText(frame, text, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, 1)\n",
    "    \n",
    "    # Compute\n",
    "    cv2.imshow('frame', frame)    \n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ba787",
   "metadata": {},
   "source": [
    "I have built some test code to test proximity threshhold before running the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c796d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This may open your webcam instead of the CrazyFlie camera! If so, try\n",
    "# # a different small, positive integer, e.g. 1, 2, 3.\n",
    "# camera = 0\n",
    "# cap = cv2.VideoCapture(camera)\n",
    "\n",
    "# # Proximity threshold for determining \"closeness\" (this could be adjusted based on your testing)\n",
    "# proximity_threshold = 500  # You can adjust this value based on the bounding box size when close to the object\n",
    "\n",
    "# while(True):\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     image_height, image_width, _ = frame.shape\n",
    "\n",
    "#     # create blob from image\n",
    "#     blob = cv2.dnn.blobFromImage(image=frame, size=(300, 300), mean=(104, 117, 123), \n",
    "#                                  swapRB=True)\n",
    "\n",
    "#     # create blob from image\n",
    "#     model.setInput(blob)\n",
    "\n",
    "#     # forward pass through the model to carry out the detection\n",
    "#     detections = model.forward()\n",
    "\n",
    "#     ########################\n",
    "#     # Variable to track if a close object is found\n",
    "#     ########################\n",
    "#     close_to_object = False\n",
    "\n",
    "\n",
    "#     # loop over each of the detection\n",
    "#     for detection in detections[0, 0, :, :]:\n",
    "#         # extract the confidence of the detection\n",
    "#         confidence = detection[2]\n",
    "#         # draw bounding boxes only if the detection confidence is above...\n",
    "#         # ... a certain threshold, else skip\n",
    "#         if confidence > .4:\n",
    "#             # get the class id\n",
    "#             class_id = detection[1]\n",
    "#             # map the class id to the class\n",
    "#             class_name = class_names[int(class_id)-1]\n",
    "#             color = COLORS[int(class_id)]\n",
    "#             # get the bounding box coordinates\n",
    "#             box_x = detection[3] * image_width\n",
    "#             box_y = detection[4] * image_height\n",
    "#             # get the bounding box width and height\n",
    "#             box_width = detection[5] * image_width\n",
    "#             box_height = detection[6] * image_height\n",
    "#             # draw a rectangle around each detected object\n",
    "#             cv2.rectangle(frame, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=1)\n",
    "#             # put the FPS text on top of the frame\n",
    "#             text = class_name + ' ' + '%.2f' % (confidence)\n",
    "#             cv2.putText(frame, text, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, 1)\n",
    "            \n",
    "#             ################\n",
    "#             # Proximity check: if the bounding box is large enough, consider it \"close\"\n",
    "#             ################\n",
    "#             if box_width > proximity_threshold or box_height > proximity_threshold:\n",
    "#                 close_to_object = True\n",
    "\n",
    "\n",
    "#     # Compute\n",
    "#     cv2.imshow('frame', frame)    \n",
    "\n",
    "#     # Print message if close to an object\n",
    "#     if close_to_object:\n",
    "#         print(\"Object is close to the camera!\")\n",
    "#     else:\n",
    "#         print(\"not close to camera\")\n",
    "\n",
    "#     # Hit q to quit.\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the capture\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e112cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "print(image_height)\n",
    "print(image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4693eff",
   "metadata": {},
   "source": [
    "### Control robot to follow central object\n",
    "\n",
    "Now we want our robot to follow an object of the specified category (e.g., person, etc.).  To do this we'll do the following\n",
    "\n",
    "1.  Detect objects matching the specified class\n",
    "2.  Select object closest to center of camera's field of vision; this is the 'target' object\n",
    "3.  Control the robot towards target object; otherwise hover\n",
    "\n",
    "We'll also create a controller that will use the distance between the target object and the center of the robot's field of view to follow the object as well as use the bounding box size to determine when to stop. \n",
    "\n",
    "First, let's define some functions that will process the images from the crazyflie. \n",
    "\n",
    "### Task 1 (10 pts) ###\n",
    "\n",
    "Fill in the function \"closest_detection\" below. This should find the detected object that is closest to the center of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d347843b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    center_x = (detection[3] + detection[5]) / 2.0 - 0.5\n",
    "    center_y = (detection[4] + detection[6]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"TODO: Find the detection closest to the image center\"\"\"\n",
    "    # Loop through and find the detection that is closest to the image center\n",
    "    # You can use the detection_center function above to find the center of the detected object\n",
    "    # Note that the origin (i.e., (x,y) = (0,0)) corresponds to the center of the image. So you can\n",
    "    # use the \"norm\" function above to find the detection that is closest to the center.\n",
    "    # Return the det that corresponds to the closest detection to the image center.\n",
    "    # If nothing is detected, return None.\n",
    "\n",
    "    if not detections:\n",
    "        return None\n",
    "\n",
    "    closest_det = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for det in detections: # Loop through and find the detection closes to center\n",
    "        center = detection_center(det) #Use detection center\n",
    "        distance = norm(center) #Compute distances \n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_det = det\n",
    "    return closest_det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f4381",
   "metadata": {},
   "source": [
    "Great, now let's get ready to control the crazyflie to follow an object! Below are a few functions to help move the crazyflie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1723ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander\n",
    "from cflib.positioning.motion_commander import MotionCommander\n",
    "\n",
    "\n",
    "def wait_for_position_estimator(scf):\n",
    "    print('Waiting for estimator to find position...')\n",
    "\n",
    "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "    log_config.add_variable('kalman.varPX', 'float')\n",
    "    log_config.add_variable('kalman.varPY', 'float')\n",
    "    log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "    var_y_history = [1000] * 10\n",
    "    var_x_history = [1000] * 10\n",
    "    var_z_history = [1000] * 10\n",
    "\n",
    "    threshold = 0.001\n",
    "    with SyncLogger(scf, log_config) as logger:\n",
    "        for log_entry in logger:\n",
    "            data = log_entry[1]\n",
    "\n",
    "            var_x_history.append(data['kalman.varPX'])\n",
    "            var_x_history.pop(0)\n",
    "            var_y_history.append(data['kalman.varPY'])\n",
    "            var_y_history.pop(0)\n",
    "            var_z_history.append(data['kalman.varPZ'])\n",
    "            var_z_history.pop(0)\n",
    "\n",
    "            min_x = min(var_x_history)\n",
    "            max_x = max(var_x_history)\n",
    "            min_y = min(var_y_history)\n",
    "            max_y = max(var_y_history)\n",
    "            min_z = min(var_z_history)\n",
    "            max_z = max(var_z_history)\n",
    "\n",
    "            print(\"{} {} {}\".\n",
    "                format(max_x - min_x, max_y - min_y, max_z - min_z))\n",
    "\n",
    "            if (max_x - min_x) < threshold and (\n",
    "                    max_y - min_y) < threshold and (\n",
    "                    max_z - min_z) < threshold:\n",
    "                break\n",
    "\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    \n",
    "    wait_for_position_estimator(cf)\n",
    "    time.sleep(0.1)    \n",
    "    return\n",
    "\n",
    "# Ascend and hover:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at 1 meter:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 1)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "def hover(cf):\n",
    "    print('Hovering:')\n",
    "    # Hover at 1 meter:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 1)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "    \n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    # Hover at 1 meter:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 1)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint()\n",
    "        time.sleep(0.1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c3203",
   "metadata": {},
   "source": [
    "### Task 2 (20 pts) ###\n",
    "\n",
    "Fill in the controller below that says \"TODO\" to make the crazyflie follow the object. The controller should use the inputs to keep the detected target in the center of its view as well determine when to stop (send True flag) so that the crazyflie stops and lands before crashing into the tracked object. (Note: the execution code implements the actual stopping using the flag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d32a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     cf: crazyflie instance\n",
    "#     box_x: x coordinate of the center of the bounding box in the image\n",
    "#     box_y: y coordinate of the center of the bounding box in the image\n",
    "#     box_width: width of the bounding box in the image\n",
    "#     box_height: height of the bounding box in the image\n",
    "#     x_cur: current x position\n",
    "#     y_cur: current y position\n",
    "    \n",
    "#     Return True to indicate that the drone is close to the target and thus exit the loop to stop and descend, new x, new y\n",
    "#     Return False to indicate continuing to follow the target, new x, new y.\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     #### TO DO: Fill below ####\n",
    "#     # Exit condition/method using size of the bounding box\n",
    "#     proximity_threshold = 300 #150 #tbd\n",
    "#     if box_width > proximity_threshold or box_height > proximity_threshold:\n",
    "#         return True, x_cur, y_cur\n",
    "    \n",
    "#     #### TO DO: Fill below ####\n",
    "#     # Determine the x and y velocity\n",
    "#     x_adjustment = -0.01 * box_x\n",
    "#     y_adjustment = -0.01 * box_y\n",
    "#     x_command = x_cur + x_adjustment\n",
    "#     y_command = y_cur + y_adjustment\n",
    "\n",
    "\n",
    "\n",
    "#     # Set velocity\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0) # Do not edit this line\n",
    "\n",
    "#     #Return false if you're not close to the target, return true if you are\n",
    "#     return False, x_command, y_command\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7020e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     Controller for moving the Crazyflie drone based on the object's position.\n",
    "\n",
    "#     cf: Crazyflie instance\n",
    "#     box_x: x-coordinate of the center of the bounding box in the image\n",
    "#     box_y: y-coordinate of the center of the bounding box in the image\n",
    "#     box_width: width of the bounding box in the image\n",
    "#     box_height: height of the bounding box in the image\n",
    "#     x_cur: current x position\n",
    "#     y_cur: current y position\n",
    "\n",
    "#     Return True to indicate that the drone is close to the target and should stop/descend,\n",
    "#     or False to continue tracking the object, and the new x, y position.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Define proximity threshold: when the bounding box is large enough to stop (object is close)\n",
    "#     proximity_threshold = 500  # Can be adjusted based on your testing\n",
    "    \n",
    "#     # If bounding box is large enough, assume we are close to the target and want to stop/descend\n",
    "#     if box_width > proximity_threshold or box_height > proximity_threshold:\n",
    "#         print(\"OMG Target is close enough. Preparing to stop or descend.\")\n",
    "#         return True, x_cur, y_cur  # Return True to exit tracking, descend, or stop\n",
    "    \n",
    "#     # # If no detection, we keep the drone hovering\n",
    "#     # if box_width == 0 or box_height == 0:\n",
    "#     #     print(\"Bruh No detection...hovering.\")\n",
    "#     #     cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)\n",
    "#     #     return False, x_cur, y_cur  # Continue hovering at the same position\n",
    "    \n",
    "#     # Calculate the x and y adjustments to move towards the target\n",
    "#     # The further the box center is from the center of the image, the stronger the correction will be\n",
    "#     x_adjustment = -0.01 * box_x  # Adjust based on the center x position\n",
    "#     y_adjustment = -0.01 * box_y  # Adjust based on the center y position\n",
    "\n",
    "#     # Compute new target positions\n",
    "#     x_command = x_cur + x_adjustment\n",
    "#     y_command = y_cur + y_adjustment\n",
    "\n",
    "#     # Send position setpoint command to Crazyflie\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)  # Z is set to 1 (e.g., 1m above the ground)\n",
    "\n",
    "#     # Return false to continue following the target, and update current positions\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f30f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     cf: crazyflie instance\n",
    "#     box_x: x coordinate of the center of the bounding box in the image\n",
    "#     box_y: y coordinate of the center of the bounding box in the image\n",
    "#     box_width: width of the bounding box in the image\n",
    "#     box_height: height of the bounding box in the image\n",
    "#     x_cur: current x position\n",
    "#     y_cur: current y position\n",
    "    \n",
    "#     Return True to indicate that the drone is close to the target and thus exit the loop to stop and descend, new x, new y\n",
    "#     Return False to indicate continuing to follow the target, new x, new y.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Calculate the size of the bounding box (which is used as an indication of distance)\n",
    "#     box_size = box_width * box_height  # Area of the bounding box\n",
    "\n",
    "\n",
    "\n",
    "#     # Define constants for the exit condition\n",
    "#     EXIT_BOX_SIZE = 50  # Threshold bounding box size to trigger stop (adjust as needed)\n",
    "#     CENTER_X = #320  # Assuming the image width is 640px, center is at 320px\n",
    "#     CENTER_Y = 240  # Assuming the image height is 480px, center is at 240px\n",
    "    \n",
    "#     # Calculate the error in position (offset from the center of the image)\n",
    "#     error_x = box_x - CENTER_X  # Horizontal error\n",
    "#     error_y = box_y - CENTER_Y  # Vertical error\n",
    "    \n",
    "#     # If the bounding box size is greater than the threshold, stop the drone\n",
    "#     if box_size > EXIT_BOX_SIZE:\n",
    "#         # If the target is big enough, we are close, so stop the drone and return True\n",
    "#         cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)  # Stop command (stay in position)\n",
    "#         return True, x_cur, y_cur\n",
    "    \n",
    "#     # Determine velocity: we can use a simple proportional controller    \n",
    "#     # Calculate the desired position adjustments based on the error\n",
    "#     x_command = x_cur + (-0.0001 * error_x)  # Adjust in x direction\n",
    "#     y_command = y_cur + (-0.0001 * error_y)  # Adjust in y direction\n",
    "\n",
    "#     # Send the new position setpoint to Crazyflie\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)  # Set position to move towards\n",
    "\n",
    "#     # Return False to continue the loop, with the new command positions\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "900a07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     EXPERIMENT\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Set proximity threshold based on object size (experimentally determined)\n",
    "#     proximity_threshold = 75  # This may need adjustment depending on the object’s distance\n",
    "\n",
    "#     # Condition to stop and land if the bounding box is close enough to the threshold size\n",
    "#     if box_width > proximity_threshold or box_height > proximity_threshold:\n",
    "#         return True, x_cur, y_cur  # Stop following and land\n",
    "\n",
    "#     # Condition to handle lost object case (when bounding box disappears or is too small)\n",
    "#     # if box_width <= 5 or box_height <= 5:\n",
    "#     #     # If the object cannot be detected reliably, stop movement to avoid risk\n",
    "#     #     return False, x_cur, y_cur\n",
    "#         #return True, x_cur, y_cur  # Stop and land if the object is lost\n",
    "\n",
    "#     # Calculate the adjustment needed to keep the object centered in the view\n",
    "#     # Adjustments scaled down for stability\n",
    "#     adjustment_factor = 0.001\n",
    "#     x_adjustment = -adjustment_factor * box_x\n",
    "#     y_adjustment = -adjustment_factor * box_y\n",
    "\n",
    "#     # New target positions based on current position\n",
    "#     # Limits are set to avoid abrupt movements\n",
    "#     x_command = x_cur + max(min(x_adjustment, 0.2), -0.2)\n",
    "#     y_command = y_cur + max(min(y_adjustment, 0.2), -0.2)\n",
    "\n",
    "#     # Command the Crazyflie to move to the calculated position\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)\n",
    "\n",
    "#     # Continue following if not yet close to the object\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cba50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     EXPERIMENT\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Set proximity threshold based on object size (experimentally determined)\n",
    "#     proximity_threshold = 100  # This may need adjustment depending on the object’s distance\n",
    "\n",
    "#     # Condition to stop and land if the bounding box is close enough to the threshold size\n",
    "#     if box_width > proximity_threshold or box_height > proximity_threshold:\n",
    "#         return True, x_cur, y_cur  # Stop following and land\n",
    "\n",
    "#     # Condition to handle lost object case (when bounding box disappears or is too small)\n",
    "#     if box_width <= 5 or box_height <= 5:\n",
    "#         # If the object cannot be detected reliably, hover in place\n",
    "#         cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)\n",
    "#         return False, x_cur, y_cur  # Continue hovering\n",
    "\n",
    "#     # Calculate the adjustment needed to keep the object centered in the view\n",
    "#     # Adjustments scaled down for stability\n",
    "#     adjustment_factor = 0.001\n",
    "#     x_adjustment = -adjustment_factor * box_x\n",
    "#     y_adjustment = -adjustment_factor * box_y\n",
    "\n",
    "#     # New target positions based on current position\n",
    "#     # Limits are set to avoid abrupt movements\n",
    "#     x_command = x_cur + max(min(x_adjustment, 0.2), -0.2)\n",
    "#     y_command = y_cur + max(min(y_adjustment, 0.2), -0.2)\n",
    "\n",
    "#     # Command the Crazyflie to move to the calculated position\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)\n",
    "\n",
    "#     # Continue following if not yet close to the object\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b61767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     Makes the drone move towards the detected object until proximity threshold is met.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Set proximity threshold based on object size (experimentally determined)\n",
    "#     proximity_threshold = 75  # Adjust this value based on object distance and size\n",
    "\n",
    "#     # Condition to check if the object is close enough to the threshold size\n",
    "#     if box_width > proximity_threshold or box_height > proximity_threshold:\n",
    "#         return True, x_cur, y_cur  # Stop moving; proximity threshold reached\n",
    "\n",
    "#     # Condition to handle lost object case (when bounding box disappears or is too small)\n",
    "#     if box_width <= 5 or box_height <= 5:\n",
    "#         # If the object cannot be detected reliably, hover in place\n",
    "#         cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)\n",
    "#         return False, x_cur, y_cur  # Continue hovering\n",
    "\n",
    "#     # Calculate the adjustment needed to move towards the object\n",
    "#     # The object's bounding box center determines the direction\n",
    "#     adjustment_factor = 0.001  # Scaling factor for smooth movements\n",
    "#     x_adjustment = -adjustment_factor * box_x  # Negative because we want to move towards center\n",
    "#     y_adjustment = -adjustment_factor * box_y\n",
    "\n",
    "#     # New target positions based on current position\n",
    "#     # Apply limits to adjustments to avoid sudden movements\n",
    "#     x_command = x_cur + max(min(x_adjustment, 0.2), -0.2)\n",
    "#     y_command = y_cur + max(min(y_adjustment, 0.2), -0.2)\n",
    "\n",
    "#     # Command the Crazyflie to move towards the calculated position\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)\n",
    "\n",
    "#     # Continue following the object\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4fe27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     cf: crazyflie instance\n",
    "#     box_x: x coordinate of the center of the bounding box in the image\n",
    "#     box_y: y coordinate of the center of the bounding box in the image\n",
    "#     box_width: width of the bounding box in the image\n",
    "#     box_height: height of the bounding box in the image\n",
    "#     x_cur: current x position\n",
    "#     y_cur: current y position\n",
    "    \n",
    "#     Return True to indicate that the drone is close to the target and thus exit the loop to stop and descend, new x, new y\n",
    "#     Return False to indicate continuing to follow the target, new x, new y.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Calculate the size of the bounding box (which is used as an indication of distance)\n",
    "#     #bounding_box_x_of_person = box_x\n",
    "\n",
    "#     current_box_size = box_width * box_height  # Area of the bounding box\n",
    "#     threshhold_box_size = 400 #291840 #245760 #40000\n",
    "\n",
    "#     # Define constants for the exit condition\n",
    "#     #center_x = image_width/2  # If im w 640px, center @ 320px\n",
    "#     #center_y = image_height/2  # If im h 480px, center @ 240px\n",
    "#     center_left_to_right = image_height/2 #image_width/2\n",
    "#     #center_\n",
    "#     total_image_size = image_width*image_height #307200\n",
    "    \n",
    "#     # Calculate the error in position (offset from the center of the image)\n",
    "#     #error_x = box_x - center_x  # Horizontal error  - once you are aligned, the center of box stays same so you should in fact do this based on size of box\n",
    "#     error_x = 2 #NEED TO REIMPLEMENT SIZE \n",
    "#     error_y = box_y - center_left_to_right  # Vertical error\n",
    "    \n",
    "#     # If the bounding box size is greater than the threshold, stop the drone\n",
    "#     if current_box_size > threshhold_box_size:\n",
    "#         # If the target is big enough, we are close, so stop the drone and return True\n",
    "#         cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)  # Stop command (stay in position)\n",
    "#         return True, x_cur, y_cur\n",
    "    \n",
    "#     # Determine velocity: we can use a simple proportional controller    \n",
    "#     # Calculate the desired position adjustments based on the error\n",
    "#     x_command = x_cur + 0*(-0.0001 * error_x)  # Adjust in x direction (this is forward on drone facing me)\n",
    "#     y_command = y_cur + (0.0001 * error_y)  # Adjust in y direction (this is left and right on drone facing me) - this is good to go\n",
    "\n",
    "#     # Send the new position setpoint to Crazyflie\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)  # Set position to move towards\n",
    "\n",
    "#     # Return False to continue the loop, with the new command positions\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a04836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     cf: crazyflie instance\n",
    "#     box_x: x coordinate of the center of the bounding box in the image\n",
    "#     box_y: y coordinate of the center of the bounding box in the image\n",
    "#     box_width: width of the bounding box in the image\n",
    "#     box_height: height of the bounding box in the image\n",
    "#     x_cur: current x position\n",
    "#     y_cur: current y position\n",
    "    \n",
    "#     Return True to indicate that the drone is close to the target and thus exit the loop to stop and descend, new x, new y\n",
    "#     Return False to indicate continuing to follow the target, new x, new y.\n",
    "#     \"\"\"\n",
    "\n",
    "#     current_box_size = box_width * box_height  # Area of the bounding box\n",
    "#     total_image_size = image_width*image_height #307200\n",
    "#     threshhold_box_w = 400 #330 #291840 #245760 #40000\n",
    "#     threshhold_box_h = 600\n",
    "\n",
    "#     # Define constants for the exit condition\n",
    "#     center_left_to_right = image_width/2 #image_height/2 #image_width/2\n",
    "    \n",
    "#     # Calculate the error in position (offset from the center of the image)\n",
    "#     error_x = current_box_size-total_image_size\n",
    "#     error_y = box_y - center_left_to_right  # Vertical error\n",
    "    \n",
    "#     # If the bounding box size is greater than the threshold, stop the drone\n",
    "#     if box_width > threshhold_box_w or box_height > threshhold_box_h: ##if current_box_size > threshhold_box_size:\n",
    "#         cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)  # Stop command (stay in position)\n",
    "#         return True, x_cur, y_cur  # If the target is big enough, we are close, so stop the drone and return True\n",
    "\n",
    "#     # Calculate the desired position adjustments based on the error (test by applying 0 on each command)    \n",
    "#     x_command = x_cur + 0*(-0.0001 * error_x)  # Adjust in x direction (this is forward on drone facing me)\n",
    "#     y_command = y_cur + -(0.0001 * error_y)  # Adjust in y direction (this is left and right on drone facing me) - this is good to go\n",
    "\n",
    "#     # Send the new position setpoint to Crazyflie\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)  # Set position to move towards\n",
    "\n",
    "#     # Return False to continue the loop, with the new command positions\n",
    "#     return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3ad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "#     \"\"\"\n",
    "#     Controller logic for forward/backward motion based on human stepping forward/backward.\n",
    "    \n",
    "#     Parameters:\n",
    "#     cf: crazyflie instance\n",
    "#     box_x: x coordinate of the center of the bounding box in the image\n",
    "#     box_y: y coordinate of the center of the bounding box in the image\n",
    "#     box_width: width of the bounding box in the image\n",
    "#     box_height: height of the bounding box in the image\n",
    "#     x_cur: current x position\n",
    "#     y_cur: current y position\n",
    "    \n",
    "#     Returns:\n",
    "#     - True to indicate that the drone should stop and descend.\n",
    "#     - False to indicate continuing to follow the target.\n",
    "#     - Updated x, y coordinates (new_x, new_y).\n",
    "#     \"\"\"\n",
    "#     # Define the reference bounding box width for \"neutral\" distance\n",
    "#     reference_box_width = 200  # Example reference width (tune as necessary)\n",
    "#     tolerance = 50  # Acceptable error margin around the reference width\n",
    "\n",
    "#     # Calculate the error between current box width and the reference\n",
    "#     width_error = box_width - reference_box_width\n",
    "\n",
    "#     # Define a proportional gain for controlling the movement\n",
    "#     k_p = 0.01  # Tune this value as needed for smooth response\n",
    "\n",
    "#     # Calculate new x position based on the error\n",
    "#     x_command = x_cur - (k_p * width_error)  # Move forward or backward based on error\n",
    "#     y_command = y_cur  # No change in y for now\n",
    "\n",
    "#     cf.commander.send_position_setpoint(x_command, y_command, 1, 0)  # Set position to move towards\n",
    "\n",
    "\n",
    "#     # Check if the drone is within the tolerance range of the target\n",
    "#     if abs(width_error) < tolerance:\n",
    "#         return True, x_command, y_command  # Stop the drone when close enough\n",
    "#     else:\n",
    "#         return False, x_command, y_command  # Continue adjusting position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3be97222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "    \"\"\"\n",
    "    cf: crazyflie instance\n",
    "    box_x: x coordinate of the center of the bounding box in the image\n",
    "    box_y: y coordinate of the center of the bounding box in the image\n",
    "    box_width: width of the bounding box in the image\n",
    "    box_height: height of the bounding box in the image\n",
    "    x_cur: current x position\n",
    "    y_cur: current y position\n",
    "    \n",
    "    Return True to indicate that the drone is close to the target and thus exit the loop to stop and descend, new x, new y\n",
    "    Return False to indicate continuing to follow the target, new x, new y.\n",
    "    \"\"\"\n",
    "\n",
    "    x_center_of_image = image_width/2\n",
    "    #y_center_of_image = image_height/2\n",
    "\n",
    "    current_box_size = box_width * box_height  # Area of the bounding box\n",
    "    total_image_size = image_width*image_height # Area of the image\n",
    "    \n",
    "    error_for_horizontal_movement = x_center_of_image-box_x\n",
    "    error_for_forwards_and_backwards_movement = current_box_size/total_image_size\n",
    "\n",
    "    \n",
    "    # If the bounding box to total image ratio is greater than the threshold, stop the drone\n",
    "    #print(error_for_forwards_and_backwards_movement)\n",
    "    if error_for_forwards_and_backwards_movement > 1.8*10**-6: #0.6: \n",
    "        print(\"DROP DROP DROP A FIFTY BAG FOR THE MOB IN THE SPOT\")\n",
    "        cf.commander.send_position_setpoint(x_cur, y_cur, 1, 0)  # Stop command (stay in position)\n",
    "        return True, x_cur, y_cur  # If the target is big enough, we are close, so stop the drone and return True\n",
    "\n",
    "    # Calculate the desired position adjustments based on the error\n",
    "    elif error_for_forwards_and_backwards_movement < 1.2*10**-6:\n",
    "        print(\"Suspected MOVE FORWARD\")\n",
    "        x_command = x_cur + (10000 * error_for_forwards_and_backwards_movement)  # Adjust in x direction (this is forward on drone facing me)\n",
    "    elif error_for_forwards_and_backwards_movement > 1.65*10**-6:\n",
    "        print(\"Suspected MOVE BACKWARD\")\n",
    "        x_command = x_cur + (-10000 * error_for_forwards_and_backwards_movement)\n",
    "    else:\n",
    "        x_command = x_cur\n",
    "\n",
    "    # x_command = x_cur\n",
    "    \n",
    "    #threshhold_for_horizontal_movement = 400 #500\n",
    "    #print(error_for_horizontal_movement)\n",
    "    # if error_for_horizontal_movement > threshhold_for_horizontal_movement:\n",
    "    #     y_command = y_cur + -(0.0000001 * error_for_horizontal_movement)  # Adjust in y direction (this is left and right on drone facing me) - this is good to go\n",
    "    # elif error_for_horizontal_movement < -threshhold_for_horizontal_movement:\n",
    "    #     y_command = y_cur + -(0.0000001 * error_for_horizontal_movement)\n",
    "    # else: \n",
    "    #     y_command = y_cur\n",
    "\n",
    "    y_command = y_cur\n",
    "\n",
    "    # Send the new position setpoint to Crazyflie\n",
    "    cf.commander.send_position_setpoint(x_command, y_command, 1, 0)  # Set position to move towards\n",
    "\n",
    "    # Return False to continue the loop, with the new command positions\n",
    "    return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde9a93",
   "metadata": {},
   "source": [
    "The following code will test your controller on the crazyflie. There are several parameters at the top that may be useful to change as indicated, otherwise do not modify the code. Please read the safety and submission instructions below before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3377304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning interfaces for Crazyflies...\n",
      "Crazyflies found:\n",
      "radio://0/1/2M\n",
      "radio://0/1/2M\n",
      "radio://0/1/2M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@258.600] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PID Controller\n",
      "Waiting for estimator to find position...\n",
      "999.999987875246 999.9999878782173 999.9997381219291\n",
      "999.999987875246 999.9999878782173 999.9997434191464\n",
      "999.999987875246 999.9999878782173 999.9997434191464\n",
      "999.9999888341135 999.9999887703634 999.9997601928335\n",
      "999.9999889602577 999.9999889597602 999.9997606851393\n",
      "999.9999894583871 999.9999894654411 999.9997649408033\n",
      "999.9999894620187 999.9999894675148 999.9997652086313\n",
      "999.9999894620187 999.9999894675148 999.9997652086313\n",
      "999.9999894620187 999.9999894675148 999.9997683609108\n",
      "1.8804912542691454e-06 1.8876125977840275e-06 3.0238981707952917e-05\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "Suspected MOVE FORWARD\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "no detection...hovering\n",
      "Hovering:\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "no detection...hovering\n",
      "Hovering:\n",
      "detection...tracking\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "detection...tracking\n",
      "Suspected MOVE BACKWARD\n",
      "no detection...hovering\n",
      "Hovering:\n",
      "detection...tracking\n",
      "DROP DROP DROP A FIFTY BAG FOR THE MOB IN THE SPOT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "\n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "                        framework='TensorFlow')\n",
    "\n",
    "# ************ Parameters that might be useful to change ************ \n",
    "# COCO label id that we want to track\n",
    "tracking_label = 1 # PERSON (1), CHAIR (62)\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "group_number = 1\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0\n",
    "\n",
    "# Confidence of detection\n",
    "confidence = 0.4 #0.4\n",
    "\n",
    "# ******************************************************************\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascend to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "\n",
    "        # capture the video\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        \n",
    "        # get the video frames' width and height\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "        # flag indicating whether to exit the main loop and then descend\n",
    "        exit_loop = False\n",
    "\n",
    "        # Ascend and hover a bit\n",
    "        set_PID_controller(cf)\n",
    "        ascend_and_hover(cf)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        x_cur = 0\n",
    "        y_cur = 0\n",
    "        \n",
    "        # detect objects in each frame of the video\n",
    "        while cap.isOpened() and not exit_loop:\n",
    "            \n",
    "            # Try to read image\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                image = frame\n",
    "                image_height, image_width, _ = image.shape\n",
    "\n",
    "                # create blob from image\n",
    "                blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), \n",
    "                                             swapRB=True)\n",
    "\n",
    "                # forward propagate image\n",
    "                model.setInput(blob)\n",
    "                detections = model.forward()\n",
    "\n",
    "                # select detections that match selected class label\n",
    "                matching_detections = [d for d in detections[0, 0] if d[1] == tracking_label]\n",
    "\n",
    "                # select confident detections\n",
    "                confident_detections = [d for d in matching_detections if d[2] > confidence]\n",
    "\n",
    "                # get detection closest to center of field of view and draw it\n",
    "                det = closest_detection(confident_detections) # This relies on the function you wrote above\n",
    "                \n",
    "                if det is not None:\n",
    "                    # get the class id\n",
    "                    class_id = det[1]\n",
    "                    # map the class id to the class \n",
    "                    class_name = class_names[int(class_id)-1]\n",
    "                    color = COLORS[int(class_id)]\n",
    "                    # get the bounding box coordinates\n",
    "                    box_x = det[3] * image_width\n",
    "                    box_y = det[4] * image_height\n",
    "                    # get the bounding box width and height\n",
    "                    box_width = det[5] * image_width\n",
    "                    box_height = det[6] * image_height\n",
    "                    # draw a rectangle around each detected object\n",
    "                    cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=2)\n",
    "                    # put the class name text on the detected object\n",
    "                    cv2.putText(image, class_name, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "                # If nothing is detected, hover\n",
    "                if det is None:\n",
    "                    print('no detection...hovering')\n",
    "                    hover(cf)\n",
    "\n",
    "                # otherwise  move towards target\n",
    "                else:\n",
    "                    print('detection...tracking')\n",
    "                    _, _, _, box_x, box_y, box_width, box_height = det\n",
    "                    box_x, box_y = detection_center(det)\n",
    "                    exit_loop, x_cur, y_cur = controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur)\n",
    "\n",
    "                # Check image\n",
    "                cv2.imshow('image', image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                print('no image!!')\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "        \n",
    "    \n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d7c43",
   "metadata": {},
   "source": [
    "<!-- If the previous cell has an error or you lose connection with your drone, run the following cell and restart the kernel. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82375b6",
   "metadata": {},
   "source": [
    "<!-- # Submission #\n",
    "\n",
    "Please submit to Gradescope \"HW8: Coding\" a zip including: this notebook Lab8 (30pts), a video (20pts see below), and Lab9 notebook (50pts).\n",
    "\n",
    "For the video, please submit the following:\n",
    "- (10 pts) A video (e.g., taken from your cellphone) showing the crazyflie following you (or any other person). The person should be moving such that it is clear the crazyflie is changing its tracking to follow the person. Read safety instructions below before trying! The crazyflie should stop and land when close to the person. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553bf6b1",
   "metadata": {},
   "source": [
    "<!-- # Safety #\n",
    "\n",
    "As always, please wear your safety glasses when working with the crazyflie. \n",
    "\n",
    "Additionally, for human tracking, please stand OUTSIDE of the netted test space. The drone's camera is capable of detecting people standing behind the net.  -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae345",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
